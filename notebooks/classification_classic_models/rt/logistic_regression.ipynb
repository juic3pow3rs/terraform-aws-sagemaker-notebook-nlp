{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create test data sample with 33k rows per sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erwin\\AppData\\Local\\Temp\\ipykernel_19584\\2556771392.py:5: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('rt_data.csv')  # Adjust path accordingly\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Load data from CSV\n",
    "df = pd.read_csv('rt_data.csv')  # Adjust path accordingly\n",
    "\n",
    "# Desired sample size of each category for top critics and non-top critics\n",
    "sample_size = 33000\n",
    "\n",
    "# Sample from top critics\n",
    "df_top_critics = df[df['top_critic'] == True].sample(\n",
    "    n=min(len(df[df['top_critic'] == True]), sample_size), random_state=42)\n",
    "\n",
    "# Sample from non-top critics\n",
    "df_not_top_critics = df[df['top_critic'] == False].sample(\n",
    "    n=min(len(df[df['top_critic'] == False]), sample_size), random_state=42)\n",
    "\n",
    "# Combine the samples\n",
    "df_balanced = pd.concat([df_top_critics, df_not_top_critics])\n",
    "\n",
    "# Shuffle the dataset\n",
    "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Save the balanced dataset to a new CSV file\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "df_balanced.to_csv(f'balanced_rt_reviews_{timestr}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def getAndTrainModel(X_train, y_train):\n",
    "    m = LogisticRegression(solver='saga', multi_class='auto', max_iter=2000, class_weight='balanced')\n",
    "    m.fit(X_train, y_train)\n",
    "    return m "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total missing or empty 'review_detail' values in the dataset: 7\n"
     ]
    }
   ],
   "source": [
    "# Loading data from a CSV file\n",
    "df = pd.read_csv('balanced_rt_reviews_20240207-193333.csv')  # Adjust the filename to your actual file path\n",
    "\n",
    "# Count the number of NaN or empty strings in 'review_detail' for the entire dataset\n",
    "missing_or_empty_count = df['review_detail'].isna().sum() + (df['review_detail'] == '').sum()\n",
    "\n",
    "# Print the count\n",
    "print(\"Total missing or empty 'review_detail' values in the dataset:\", missing_or_empty_count)\n",
    "\n",
    "df = df.dropna(subset=['review_detail'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df['review_detail'].values\n",
    "# If 'top_critic' is boolean, you can directly use it as an integer target variable\n",
    "top_critics = df['top_critic'].astype(int).values  # Converts boolean to 0 (False) and 1 (True)\n",
    "\n",
    "# Vectorizing text data\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(texts)\n",
    "\n",
    "# Splitting dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, top_critics, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ensure the test set is not too small\n",
    "if X_test.shape[0] < 1:\n",
    "    raise ValueError(\"Test set is too small. Consider reducing the test_size parameter or adding more data.\")\n",
    "\n",
    "# Training a model with adjusted parameters\n",
    "model = getAndTrainModel(X_train=X_train, y_train=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5849685582241079\n",
      "ROC AUC score: 0.5851587288466016\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.59      0.56      0.58      6660\n",
      "        True       0.58      0.61      0.59      6539\n",
      "\n",
      "    accuracy                           0.58     13199\n",
      "   macro avg       0.59      0.59      0.58     13199\n",
      "weighted avg       0.59      0.58      0.58     13199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Predicting\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Evaluating with accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate and print MAE\n",
    "ra = roc_auc_score(y_test, predictions)\n",
    "print(\"ROC AUC score:\", ra)\n",
    "\n",
    "\n",
    "# Generating and printing the classification report\n",
    "report = classification_report(y_test, predictions, target_names=[\"False\",\"True\"])\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
